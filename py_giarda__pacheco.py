# -*- coding: utf-8 -*-
"""Py_Giarda _Pacheco

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13uBKqCHoHg70lEFbSQY6PZAwNMOaSgJZ

[HPA](https://www.kaggle.com/competitions/hpa-single-cell-image-classification/data)


[Notebook para plotear](https://www.kaggle.com/code/lnhtrang/hpa-public-data-download-and-hpacellseg/notebook)

[Dataset](https://www.kaggle.com/datasets/bddccd08650904608a79de7ed054136e6c1f4fe6a6ad893abe976772d3e7389d?select=cells.7z)

El conjunto de datos utilizado se origina en el "Human Protein Atlas - Single Cell Classification". El objetivo principal del desafío era clasificar las células extraídas de imágenes de tejidos humanos, y mapear proteínas en células y tejidos.  Diferentes distribuciones subcelulares de una proteína pueden dar lugar a una gran heterogeneidad funcional entre células. Encontrar tales diferencias y descubrir cómo y por qué ocurren es importante para comprender cómo funcionan las células, cómo se desarrollan las enfermedades y, en última instancia, cómo desarrollar mejores tratamientos para esas enfermedades.

El conjunto de datos originales se adquiere de una manera altamente estandarizada utilizando una modalidad de imagen (microscopía confocal). Sin embargo, comprende 17 tipos de células de morfología muy diferente, que afectan los patrones de las proteínas de los diferentes orgánulos. Todas las muestras de imágenes están representadas por cuatro filtros, la proteína de interés (verde) más tres puntos de referencia celulares: núcleo (azul), microtúbulos (rojo) y retículo endoplásmico (amarillo).

El objetivo principal de este conjunto de datos nuevo es proporcionar ejemplos etiquetados para permitir que otros mejoren sus sistemas. Se generó mediante el etiquetado manual de ~9600 imágenes. En este proceso, a cada celda se le dio una de las dos etiquetas: 0 o 1, dependiendo de si era adecuada para un procesamiento posterior. El criterio principal para esta decisión fue la cantidad de información visual capturada por el algoritmo de segmentación, en particular, al menos el 50% del núcleo tenía que estar presente.

Columnas del dataset:

Las primeras columnas hacen referencia a valores de la imagen en general, o de la proteína:

isBad: valor 0 o 1, indica si la imagen es adecuada para el procesamiento;

heights: altura de la imagen;

widths: ancho de la imagen;

aspect_ratio: proporción entre la altura y el ancho de una imágen;

bbox_area: área definida por el bounding box;

mask_area: área de la proteína;

mask_perimeters: perímetro de la proteína;

compactenesses: medida de compacidad de la proteína.

Las sigueintes características hacen referencia a las imágenes obtenidas de acuerdo a cada uno de los cuatro filtros, teniendo en cuenta la cantidad de puntos y la intensidad de los colores:

red_pts, green_pts, blue_pts, yellow_pts: cantidad de puntos;

red_ratio, green_ratio, blue_ratio, yellow_ratio, gb2all_ratio: radio del color en el número total de puntos;

red_pts_mean, green_pts_mean, blue_pts_mean, yellow_pts_mean: intensidad media;

red_pts_max, green_pts_max, blue_pts_max, yellow_pts_max: intensidad máxima;

max_bg, max_dim: hacen referencia a características del background que no se especifican.

No fue necesario quitar columnas del dataset para realizar el trabajo. En paralelo, aplicamos PCA a los datos para poder hacer comparaciones en algunos métodos.

#Importing and Splitting
"""

#Drive
from google.colab import drive
drive.mount('/content/drive')

#Miscelaneo
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statistics
from sklearn.model_selection import train_test_split

#Metrics
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    precision_score,
    ConfusionMatrixDisplay,
    f1_score,
    classification_report
)
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import PrecisionRecallDisplay

#Processing
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

dat = '/content/drive/Shareddrives/Proyectou/Bad Cell/cell_stats_with_gt.csv'
baddie = pd.read_csv(dat)

from sklearn import set_config
set_config(transform_output="pandas") #para que queden los feature names

target_names = ['Well Segmented','Bad Segmented']

x = baddie.drop(['isBad','Id'],axis=1)
y = baddie['isBad']
Id = baddie['Id']
feature_names = x.columns

#split
x_train, x_test, y_train, y_test, Id_train, Id_test = train_test_split(x, y, Id, test_size=0.25, random_state=142)

#nombres de la imagenes
Id_train, Id_test = np.array(Id_train),np.array(Id_test)

#scaling
scaler = StandardScaler()
x = scaler.fit_transform(x)
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x.shape

"""#PCA"""

#pca de 10 componentes
pca = PCA(n_components = 10,svd_solver = 'randomized',whiten=False)
pca.fit(x)
plt.plot(np.cumsum(pca.explained_variance_ratio_),color='r')
plt.xlabel('Components')
plt.ylabel('Varianza');

n_components = 7
pca = PCA(n_components = n_components,svd_solver = 'randomized',whiten=False )
pca.fit(x)
components = pca.transform(x)

plt.figure()
colors = ["b","pink"]
lw = 2

for color, i, target_name in zip(colors, [0, 1], target_names):
    plt.scatter(
        np.array(components)[y == i, 0], np.array(components)[y == i, 1], color=color, alpha=0.8, lw=lw, label=target_name
    )
plt.legend(loc="best", shadow=False, scatterpoints=1)
plt.title("Primeras dos Componentes de PCA")

plt.show();

#Transformamos el Train y Test
x_train_pca = np.array(pca.fit(x_train).transform(x_train))
x_test_pca = np.array(pca.transform(x_test))

"""# Some Definiciones for Later"""

#shoutout to chatgpt
def twistor(y_test, y_pred1,y_pred2):
  a = np.where(np.logical_and(np.logical_and(y_pred1 == 0, y_test == 1),y_pred2 == 1))[0] # False Well vs True Bad (recall)
  b = np.where(np.logical_and(np.logical_and(y_pred1 == 1, y_test == 0),y_pred2 == 0))[0] # False Bad vs True Well (precision)
  c = np.where(np.logical_and(np.logical_and(y_pred1 == 0, y_test == 1),y_pred2 == 0))[0] # Diff Recall
  d = np.where(np.logical_and(np.logical_and(y_pred1 == 1, y_test == 0),y_pred2 == 1))[0] # Diff Precision
  return a,b,c,d

def cellplot(sample_place,subplace):

  #rading images
  im3 = '/content/drive/Shareddrives/Proyectou/Bad Cell/cells/%s_red.png' %Id_test[subplace[sample_place]]
  microtubule = plt.imread(im3)
  endoplasmicrec = plt.imread(im3.replace('_red','_yellow'))
  nuclei = plt.imread(im3.replace('_red','_blue'))
  mask = plt.imread(im3.replace('_red','_green'))
  img = np.dstack((microtubule, endoplasmicrec, nuclei))

  fiumba=[microtubule, endoplasmicrec, nuclei, mask]
  channels=['microtubule(red)', 'er(yellow)', 'nuclei(blue)', 'protein(green)']

  fig = plt.figure(layout="constrained")

  #macroo
  gs0 = fig.add_gridspec(1, 2)

  #right(merged)
  gs1 = gs0[1].subgridspec(1,1)

  ax1 = fig.add_subplot(gs1[0])
  ax1.imshow(img)
  ax1.imshow(mask, alpha=0.5)
  ax1.axis('off')

  #left(channels)
  gs2 = gs0[0].subgridspec(4, 1)

  for ss, im, chan in zip(gs2,fiumba,channels):

      ax = fig.add_subplot(ss)
      ax.imshow(im,cmap='gray')
      ax.axis('off')
      ax.set_title("%s"%chan)

  ax.set_xlabel("x-label", fontsize=12)

bad = np.where(y==1)[0]
bad
well = np.where(y==0)[0]

#5
for i in range(10,20):
  cellplot(i,well)

"""#Lets Beggin...

El primer clasificador utilizado, dummy, al ser tan simple, nos aporta una base para poder comparar otros clasificadores más complejos.
"""

# Clasificador Dummy
from sklearn.dummy import DummyClassifier

clf = DummyClassifier(strategy='most_frequent', random_state=0)
clf.fit(x_train, y_train)
clf.score(x_test,y_test)

"""##NB

El siguiente clasificador es Naive Bayes, lo elegimos porque es un método rápido y sencillo para clasificar.
"""

from sklearn.naive_bayes import GaussianNB
NB = GaussianNB()
NB.fit(x_train,y_train)
y_pred_nb = NB.predict(x_test)


print(classification_report(y_test,
                            y_pred_nb,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_nb,
                                        display_labels=target_names,ax=ax[0],cmap='Reds')

RocCurveDisplay.from_estimator(NB , x_test, y_test,ax=ax[1],color='#800000')





PrecisionRecallDisplay.from_estimator(NB, x_test, y_test,ax=ax[1],color='#F08080')

plt.tight_layout();
plt.show();

#cohen_kappa_score(y_test,y_pred_nb)

NBr = GaussianNB().fit(x_train_pca,y_train)
y_pred_nb_pca = NBr.predict(x_test_pca)

print(classification_report(y_test,
                            y_pred_nb_pca,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_nb_pca,
                                        display_labels=target_names,ax=ax[0],cmap='Reds')

RocCurveDisplay.from_estimator(NBr,
                               x_test_pca,
                               y_test,ax=ax[1],color='#800000')


PrecisionRecallDisplay.from_estimator(NBr,
                                      x_test_pca,
                                      y_test,ax=ax[1],color='#F08080')
plt.tight_layout();
plt.show();

"""Como podemos ver, al utilizar PCA aumentan los valores de AUC y AP, es muy notoria la mejoría en la clasificación de los 'well segmented' pero a costa de un claro desmejoramiento de clasificación de los 'bad segmented'.

##Tree

La complejidad del clasificador decision tree es mayor a Naive Bayes, pero menor a otros clasificadores que utilizaremos a continuación. Al tener tantas características en la base de datos, y como el árbol elige las más significativas, esperamos que de un buen resultado en este modelo.
"""

from sklearn.tree import DecisionTreeClassifier

clfs = []
depths = [3,4,5,6,7,8,9,10] # profundidades maximas

#creamos los clf segun el depth
for i in depths:
    clf = DecisionTreeClassifier(random_state=0,class_weight='balanced',max_depth = i)
    clf.fit(x_train, y_train)
    clfs.append(clf)

clfs = clfs[:-1]
depths = depths[:-1]

#score de cada clf
train_scores = [clf.score(x_train, y_train) for clf in clfs]
test_scores = [clf.score(x_test, y_test) for clf in clfs]

#plott
fig, ax = plt.subplots(figsize=(10,4))
ax.set_xlabel("max_depth")
ax.set_ylabel("accuracy")
ax.set_title("Accuracy vs Max Depth of Tree for training and testing sets")
ax.plot(depths, train_scores, marker="o", label="train", drawstyle="steps-post")
ax.plot(depths, test_scores, marker="o", label="test", drawstyle="steps-post")
ax.legend()
plt.show()

"""Es notable que con una profundiad mayor a 6, las mejoras del clasificador no son tan notorias y es más probable un sobreajuste, por lo que seleccionamos max_depth = 6."""

max_depth = 6
clf = DecisionTreeClassifier(random_state=0,max_depth=max_depth,class_weight='balanced')
#Effective Alphas and Impurities
path = clf.cost_complexity_pruning_path(x_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

#creamos los clf segun el alpha
clfs = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha,max_depth=max_depth,class_weight='balanced')
    clf.fit(x_train, y_train)
    clfs.append(clf)

clfs = clfs[:-1]
ccp_alphas = ccp_alphas[:-1]

train_scores = [clf.score(x_train, y_train) for clf in clfs]
test_scores = [clf.score(x_test, y_test) for clf in clfs]


fig, ax = plt.subplots(figsize=(15,4))
plt.xticks(ccp_alphas,rotation='vertical')
ax.set_xlabel("alpha")
ax.set_ylabel("accuracy")
ax.set_title("Accuracy vs Alpha for training and testing sets")
ax.plot(ccp_alphas, train_scores, marker="o", label="train", drawstyle="steps-post")
ax.plot(ccp_alphas, test_scores, marker="o", label="test", drawstyle="steps-post")
ax.legend()
plt.show()

#zoom del plot
fig, ax = plt.subplots(figsize=(15,5))
plt.xticks(ccp_alphas,rotation='vertical')
ax.set_xlabel("alpha")
ax.set_ylabel("accuracy")
ax.set_title("Accuracy vs Alpha for training and testing sets")
ax.plot(ccp_alphas, train_scores, marker="o", label="train", drawstyle="steps-post")
ax.plot(ccp_alphas, test_scores, marker="o", label="test", drawstyle="steps-post")
ax.legend()
plt.xlim(0,0.0027)
plt.ylim(0.8,0.88)
plt.show()

Tree = DecisionTreeClassifier(class_weight='balanced',
                              criterion='entropy',random_state=0,max_depth=7,
                              ccp_alpha=0.00156
                              )
Tree.fit(x_train,y_train)

y_pred_tree = Tree.predict(x_test)


print(classification_report(y_test,
                            y_pred_tree,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_tree,
                                        display_labels=target_names,ax=ax[0],cmap='Paired')

RocCurveDisplay.from_estimator(Tree ,
                               x_test,
                               y_test,ax=ax[1],color='#CD853F')


PrecisionRecallDisplay.from_estimator(Tree,
                                      x_test,
                                      y_test,ax=ax[1],color='#FFE4B5')
plt.tight_layout();
plt.show();

"""Podemos ver un gran aumento de los valores respecto a los obtenidos en Naive Bayes."""

from sklearn import tree

plt.figure(figsize=(20,20))
tree.plot_tree(Tree, filled = True,feature_names = feature_names,class_names=target_names,max_depth=2);

from sklearn.feature_selection import SelectFromModel
selector = SelectFromModel(estimator=Tree).fit(x_train, y_train)
print(selector.get_feature_names_out())

"""En función del árbol obtenido, podemos ver que para este método las características que mayor información brindan son mask_perimeters, compactnesses, blue_ratio y max_dim.

Graficamos a continuación los datos en el plano considerando mask_perimeters y compactnesses.
"""

fig = plt.figure()
ax = fig.add_subplot()
ax.set_xlabel('mask_perimeters')
ax.set_ylabel('compactnesses')

colors = ["b","pink"]
lw = 2

for color, i, target_name in zip(colors, [0, 1], target_names):
    ax.scatter(
        np.array(x['mask_perimeters'])[y == i],
        np.array(x['compactnesses'])[y == i],
        color=color, alpha=0.8, lw=lw, label=target_name)
plt.legend(loc="best", shadow=False, scatterpoints=1)

plt.show();

"""##LR

El próximo método elegido es logistic regression, pues es útil para predecir la presencia o ausencia de una característica o variable dicotómica (en este caso isBad = 0 ó 1). Al usar logistic regression con cross validation, nos aseguramos obtener mejores resultados y a su vez no tenemos que hacer el cálculo del gridsearch.
"""

from sklearn.linear_model import LogisticRegressionCV

LR = LogisticRegressionCV(class_weight='balanced',cv=5, penalty='l2', solver='liblinear', tol=1e-6, max_iter=int(1e6))
LR.fit(x_train,y_train)

y_pred_lr = LR.predict(x_test)


print(classification_report(y_test,
                            y_pred_lr,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_lr,
                                        display_labels=target_names,ax=ax[0],cmap='Oranges')
RocCurveDisplay.from_estimator(LR,
                               x_test,
                               y_test,ax=ax[1],color='#CC6600')


PrecisionRecallDisplay.from_estimator(LR,
                                      x_test,
                                      y_test,ax=ax[1],color='#FFB266')
plt.tight_layout();
plt.show();

"""El valor obtenido de AUC = 0.92 nos indica que el método está clasificando de una muy buena manera, aunque notamos una clara desventaja hacia la categoría bad segmented, al tratarse de la menos frecuente.

##SVM

Los clasificadores de suport vector machine tienen un muy buen rendimiento en modelos de clasificación binaria.
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.model_selection import GridSearchCV


#gridsearch
C_range = np.logspace(0, 2, 5)
gamma_range = np.logspace(-4, -2, 4)
param_grid = dict(gamma=gamma_range,C=C_range)

cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, train_size=0.3, random_state=42)
grid = GridSearchCV(SVC(class_weight='balanced'), param_grid=param_grid, cv=cv) #radial basis function
grid.fit(x_train, y_train)

print(
    "The best parameters are %s with a score of %0.2f"
#     % (grid.best_params_, grid.best_score_)
)

SVM = SVC(C=100.0,gamma= 0.002,class_weight='balanced')
SVM.fit(x_train,y_train)

y_pred_svm = SVM.predict(x_test)


print(classification_report(y_test,
                            y_pred_svm,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_svm,
                                        display_labels=target_names,ax=ax[0],cmap='Blues')
RocCurveDisplay.from_estimator(SVM,
                               x_test,
                               y_test,ax=ax[1],color='#3333FF')


PrecisionRecallDisplay.from_estimator(SVM,
                                      x_test,
                                      y_test,ax=ax[1],color = '#6666FF')
plt.tight_layout();
plt.show();

"""Con el clasificador SVM obtenemos el mejor valor para el AUC = 0.93, aunque no alcanza los 0.95 que esperábamos.

##Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
Forest = RandomForestClassifier(criterion = 'entropy',
                                max_features = 'sqrt',
                                n_estimators = 100,
                                max_depth = 25,
                                min_samples_leaf = 3,
                                oob_score=True,
                                class_weight = 'balanced',
                                random_state=0)

Forest.fit(x_train,y_train)
y_pred_rf = Forest.predict(x_test)


print(classification_report(y_test,
                            y_pred_rf,
                            target_names=target_names))

fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_rf,
                                        display_labels=target_names,ax=ax[0],cmap='Greens')
RocCurveDisplay.from_estimator(Forest,
                               x_test,
                               y_test,ax=ax[1],color='green')


PrecisionRecallDisplay.from_estimator(Forest,
                                      x_test,
                                      y_test,ax=ax[1],color='#B2FF66')
plt.tight_layout();
plt.show();

"""Con este clasificador obtuvimos el mayor valor del average precision = 0.82. Si bien el valor del AUC es menor a SVC, el tener un valor de AP mayor indica que está tratando mejor el desbalanceo de las clases."""

selector = SelectFromModel(estimator=Forest).fit(x_train, y_train)
print(selector.get_feature_names_out())

"""Respecto a als características consideradas más importantes, si bien agrega más características a las seleccionadas por otros métodos, 'compactnesses' y 'mask_perimeters' coinciden en todos.

#Results

##roc's y ...
"""

fig, ax = plt.subplots(1,2,figsize=(10,4))

RocCurveDisplay.from_estimator(NBr,x_test_pca,y_test,ax=ax[0],color='#800000')
PrecisionRecallDisplay.from_estimator(NBr,x_test_pca,y_test,ax=ax[1],color='#F08080')
plt.tight_layout();

for est,color in zip([Tree,
                      LR,
                      SVM,
                      Forest],
                       [['#CD853F','#FFE4B5']
                       ,['#CC6600','#FFB266']
                       ,['#3333FF','#6666FF']
                       ,['green'  ,'#B2FF66']]):

  RocCurveDisplay.from_estimator(est,x_test,y_test,ax=ax[0],color=color[0])
  PrecisionRecallDisplay.from_estimator(est,x_test,y_test,ax=ax[1],color=color[1])
  plt.tight_layout();


plt.show();

"""Al comparar las curvas obtenidas, es claro que para este dataset el peor clasificador es Naive Bayes. Respecto al método que mejor clasificó, si bien SVC obtiene el máximo valor para AUC, random forest obtiene el mejor valor para AP y un valor alto de AUC. Además, comparando los valores  por lo que podemos concluir que es el método que mejor clasificó nuestrso datos.

##tree vs forest
"""

import random
rec,prec,drec,dprec = twistor(y_test,y_pred_tree,y_pred_rf)

"""###False Well de tree, True Bad del forest

Queremos resaltar la mejoría que obtenemos utilizando random forest en lugar de decision tree.
Presentamos imágenes (junto con sus filtros) de ejemplos mal clasificados por decision tree pero bien clasificados por random forest.

En estos primeros dos ejemplos, son imágenes que corresponden con 'bad segmentation', random forest las clasificó bien  y decision tree como 'well segmentation'.
"""

randrec = random.sample(range(0,len(rec)), 4)
for i in randrec:
  cellplot(i,rec)

"""###False Bad de tree, True Well del forest

Las siguientes imágenes corresponden a 'Well segmentation', random forest las clasificó bien y decision tree las clasificó como 'bad segmentation'.
"""

randprec = random.sample(range(0,len(prec)),4)
for i in randprec:
  cellplot(i,prec)

"""##svm vs forest"""

rec,prec,drec,dprec = twistor(y_test,y_pred_svm,y_pred_rf)

"""A continuación, presentamos ejemplos de imágenes mal clasificadas tanto por random forest como por support vector machine.

###False Well para svm y forest

Ambos clasifican la imagen como 'well segmentation' cuando se trata de 'bad segmentation'.
"""

randdrec = random.sample(range(0,len(drec)),4)
for i in randdrec:
  cellplot(i,drec)

"""###False Bad para svm y forest

Ambos clasifican la imagen como 'bad segmentation' cuando se trata de 'well segmentation'.
"""

randdprec = random.sample(range(0,len(dprec)),4)
for i in randdprec:
  cellplot(i,dprec)

#macroo
gs0 = fig.add_gridspec(2, 1)

#right(merged)
gs1 = gs0[0].subgridspec(1,4)

ax1=fig.add_subplot(gs1[0])
ax1=cellplot(20,rec)
ax1=fig.add_subplot(gs1[0])
ax1=cellplot(21,rec)

#right(merged)
gs1 = gs0[1].subgridspec(1,4)

ax1=fig.add_subplot(gs1[0])
ax1=cellplot(20,rec)
ax1=fig.add_subplot(gs1[0])
ax1=cellplot(21,rec)

rec,prec,drec,dprec = twistor(y_test,y_pred_svm,y_pred_rf)
cellplot(20,drec)
cellplot(20,dprec)

"""#XGB

El método elegido por los creadores de la base de datos para testear mejorías en el modelo fue XGBoost, con el cuál obtuvieron un 95% de AUC.
Por lo tanto, decidimos probar este clasificador para poder comparar resultados.
"""

import xgboost as xgb

XGB = xgb.XGBClassifier(objective="binary:logistic", random_state=42)
XGB.fit(x_train,y_train)

y_pred_xgb = XGB.predict(x_test)


print(classification_report(y_test,
                            y_pred_xgb,
                            target_names=target_names))


fig, ax = plt.subplots(1,2,figsize=(10,4))
ConfusionMatrixDisplay.from_predictions(y_test,
                                        y_pred_xgb,
                                        display_labels=target_names,ax=ax[0],cmap='Greys')
RocCurveDisplay.from_estimator(XGB,
                               x_test,
                               y_test,ax=ax[1],color='black')


PrecisionRecallDisplay.from_estimator(XGB,
                                      x_test,
                                      y_test,ax=ax[1],color = 'gray')
plt.tight_layout();
plt.show();

cohen_kappa_score(y_test,y_pred_xgb)

"""A pesar de haber obtenido un muy buen valor de  AUC = 0.92, es menor al valor de referencia que teníamos (0.95)."""

selector = SelectFromModel(estimator=XGB).fit(x_train, y_train)
print(selector.get_feature_names_out())

xgb.plot_importance(XGB);

"""Podemos ver que las dos características de mayor importancia, mask_perimeters y compactenesses, coinciden con las dadas por el árbol de decisión.

# Conclusiones

El objetivo principal del desafío inicial era clasificar las células extraídas de imágenes de tejidos humanos. La mayoría de los participantes utilizó el método de segmentación, pero las células falsamente segmentadas tuvieron un efecto negativo en los puntajes de evaluación. La solución fue crear un método automatizado para detectar dichas células y tratarlas en consecuencia. Al adoptar alguna forma de este enfoque, varios equipos pudieron aumentar significativamente sus puntajes.

El objetivo principal de este proyecto, fue separar las imágenes de las células en función de la información presente en la imagen, para decidir si la célula es adecuada para un procesamiento posterior o no, el cuál es un posible trabajo a futuro.

Con los resultados obtenidos, vemos que casi todos los métodos, excepto Naive Bayes, obtienen valores altos de AUC, pero el clasificador que obtiene un mayor valor del average-precision es random forest, por lo que podemos considerarlo como el mejor clasificador para nuestro dataset. Que hayan obtenido un valor alto de AUC y no de AP puede deberse a que el dataset está desbalanceado.

En cuánto al éxito, tenemos en cuenta dos métricas:

-objetiva: el proyecto fue casi exitoso, hasta los métodos más básicos dieron una buena clasificación de los datos, por lo cual consideramos que no era una tarea complicada, lo difícil es mejorar los resultados, y no llegamos al resultado obtenido por los autores del paper;

-personal: el proyecto fue exitoso en términos de aprendizaje.
"""